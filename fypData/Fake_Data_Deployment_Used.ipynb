{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f1387f",
   "metadata": {},
   "source": [
    "##### Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc2212f",
   "metadata": {},
   "source": [
    "#### Generate new fake data (4500 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343caa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution completed in 55.71 seconds\n",
      "\n",
      "Resignation date distribution:\n",
      "Resignation_Date\n",
      "01/01/2018    14\n",
      "01/01/2019    10\n",
      "01/01/2020    19\n",
      "01/01/2021    18\n",
      "01/01/2022    19\n",
      "              ..\n",
      "31/12/2020    17\n",
      "31/12/2021    20\n",
      "31/12/2022    20\n",
      "31/12/2023    16\n",
      "31/12/2024    19\n",
      "Name: count, Length: 2738, dtype: int64\n",
      "\n",
      "Total records: 104500\n",
      "Resigned employees: 42578\n",
      "  - Q1 2025 resignations (Jan-Mar): 805\n",
      "  - Q2 2025 resignations (Apr-Jun): 478\n",
      "  - Other resignations: 41295\n",
      "Current employees (no resignation date): 61922\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import time\n",
    "\n",
    "# Original dataset\n",
    "df = pd.read_csv('Extended_Employee_Performance_and_Productivity_Data.csv')\n",
    "df['Hire_Date'] = pd.to_datetime(df['Hire_Date'], dayfirst=True).dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Initialize Faker for realistic fake data\n",
    "fake = Faker()\n",
    "\n",
    "# Precompute department-job title mappings for faster access\n",
    "dept_job_mapping = df.groupby('Department')['Job_Title'].unique().to_dict()\n",
    "job_edu_mapping = df.groupby('Job_Title')['Education_Level'].unique().to_dict()\n",
    "job_perf_salary_mapping = df.groupby(['Job_Title', 'Performance_Score'])['Monthly_Salary'].apply(list).to_dict()\n",
    "\n",
    "def generate_new_records_fast(n):\n",
    "    emp_ids = np.arange(1000000, 1000000 + n)\n",
    "    \n",
    "    # Sample departments and genders\n",
    "    departments = np.random.choice(df['Department'].unique(), size=n)\n",
    "    genders = np.random.choice(df['Gender'].unique(), size=n)\n",
    "    \n",
    "    # Get job titles based on departments\n",
    "    job_titles = np.array([np.random.choice(dept_job_mapping[dept]) for dept in departments])\n",
    "    \n",
    "    # Generate ages, years at company within 1 years\n",
    "    ages = np.random.randint(20, 60, size=n)\n",
    "    years_at_company = np.random.randint(0, 1, size=n)\n",
    "    \n",
    "    # Generate hire dates between July 1, 2024 to July 1, 2025 \n",
    "    start_date = pd.to_datetime('2024-07-01')\n",
    "    end_date = pd.to_datetime('2025-07-01')\n",
    "    date_range = (end_date - start_date).days\n",
    "    random_days = np.random.randint(0, date_range + 1, size=n)  \n",
    "    hire_dates = pd.Series(start_date + pd.to_timedelta(random_days, unit='D')).dt.strftime('%d/%m/%Y')\n",
    "    \n",
    "    # Get education levels based on job titles\n",
    "    educations = np.array([np.random.choice(job_edu_mapping.get(job, df['Education_Level'].unique())) \n",
    "                         for job in job_titles])\n",
    "    \n",
    "    # Generate performance scores\n",
    "    performances = np.random.choice([1, 2, 3, 4, 5], size=n)\n",
    "    \n",
    "    # Get salaries based on job title and performance\n",
    "    salaries = np.array([\n",
    "        np.random.choice(job_perf_salary_mapping.get((job, perf), df[df['Job_Title'] == job]['Monthly_Salary'].values))\n",
    "        for job, perf in zip(job_titles, performances)\n",
    "    ])\n",
    "    \n",
    "    # Generate other fields\n",
    "    work_hours = np.random.randint(30, 60, size=n)\n",
    "    projects = np.random.randint(0, 50, size=n)\n",
    "    overtime = np.random.randint(0, 30, size=n)\n",
    "    sick_days = np.random.randint(0, 15, size=n)\n",
    "    remote_freq = np.random.randint(30, 80, size=n)\n",
    "    team_size = np.random.randint(1, 20, size=n)\n",
    "    training_hours = np.random.randint(0, 20, size=n)\n",
    "    promotions = np.random.randint(0, 3, size=n)\n",
    "    satisfaction = np.round(np.random.uniform(1, 5, size=n), 2)\n",
    "    \n",
    "    new_data = pd.DataFrame({\n",
    "        'Employee_ID': emp_ids,\n",
    "        'Department': departments,\n",
    "        'Gender': genders,\n",
    "        'Age': ages,\n",
    "        'Job_Title': job_titles,\n",
    "        'Hire_Date': hire_dates,\n",
    "        'Years_At_Company': years_at_company,\n",
    "        'Education_Level': educations,\n",
    "        'Performance_Score': performances,\n",
    "        'Monthly_Salary': salaries,\n",
    "        'Work_Hours_Per_Week': work_hours,\n",
    "        'Projects_Handled': projects,\n",
    "        'Overtime_Hours': overtime,\n",
    "        'Sick_Days': sick_days,\n",
    "        'Remote_Work_Frequency': remote_freq,\n",
    "        'Team_Size': team_size,\n",
    "        'Training_Hours': training_hours,\n",
    "        'Promotions': promotions,\n",
    "        'Employee_Satisfaction_Score': satisfaction,\n",
    "        'Resigned': False\n",
    "    })\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate 4,500 new records with July 2024-July 2025 hire dates\n",
    "new_records = generate_new_records_fast(4500)\n",
    "\n",
    "# Combine with original data\n",
    "extended_df = pd.concat([df, new_records], ignore_index=True)\n",
    "extended_df['Hire_Date'] = pd.to_datetime(extended_df['Hire_Date'], dayfirst=True)\n",
    "\n",
    "# Create Resignation_Date column (initially empty)\n",
    "extended_df['Resignation_Date'] = pd.NaT\n",
    "\n",
    "# Get all resigned employees\n",
    "resigned_mask = extended_df['Resigned'] == True\n",
    "resigned = extended_df[resigned_mask]\n",
    "\n",
    "# Randomly select 805 for Q1 (Jan-Mar 2025) and 478 for Q2 (Apr-Jun 2025)\n",
    "q1_resignations = resigned.sample(805, random_state=42)\n",
    "remaining_resigned = resigned.drop(q1_resignations.index)\n",
    "q2_resignations = remaining_resigned.sample(478, random_state=42)\n",
    "other_resignations = remaining_resigned.drop(q2_resignations.index)\n",
    "\n",
    "# Assign Q1 resignation dates (Jan-Mar 2025)\n",
    "q1_start = pd.to_datetime('01/01/2025', dayfirst=True)\n",
    "q1_end = pd.to_datetime('31/03/2025', dayfirst=True)\n",
    "days_in_q1 = (q1_end - q1_start).days\n",
    "random_days = np.random.randint(0, days_in_q1 + 1, size=len(q1_resignations))\n",
    "extended_df.loc[q1_resignations.index, 'Resignation_Date'] = q1_start + pd.to_timedelta(random_days, unit='D')\n",
    "\n",
    "# Assign Q2 resignation dates (Apr-Jun 2025)\n",
    "q2_start = pd.to_datetime('01/04/2025', dayfirst=True)\n",
    "q2_end = pd.to_datetime('30/06/2025', dayfirst=True)\n",
    "days_in_q2 = (q2_end - q2_start).days\n",
    "random_days = np.random.randint(0, days_in_q2 + 1, size=len(q2_resignations))\n",
    "extended_df.loc[q2_resignations.index, 'Resignation_Date'] = q2_start + pd.to_timedelta(random_days, unit='D')\n",
    "\n",
    "# Assign random past dates for other resignations (before 2025)\n",
    "past_start = pd.to_datetime('01/01/2018', dayfirst=True)  \n",
    "past_end = pd.to_datetime('31/12/2024', dayfirst=True)\n",
    "days_in_past = (past_end - past_start).days\n",
    "random_days = np.random.randint(0, days_in_past + 1, size=len(other_resignations))\n",
    "extended_df.loc[other_resignations.index, 'Resignation_Date'] = past_start + pd.to_timedelta(random_days, unit='D')\n",
    "extended_df['Hire_Date'] = extended_df['Hire_Date'].dt.strftime('%d/%m/%Y')\n",
    "extended_df['Resignation_Date'] = extended_df['Resignation_Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "extended_df.to_csv('Deployment_Used_Extended_Dataset_with_Resignation.csv', index=False)\n",
    "\n",
    "print(f\"Execution completed in {time.time() - start_time:.2f} seconds\")\n",
    "print(\"\\nResignation date distribution:\")\n",
    "print(extended_df[resigned_mask]['Resignation_Date'].value_counts().sort_index())\n",
    "print(f\"\\nTotal records: {len(extended_df)}\")\n",
    "print(f\"Resigned employees: {resigned_mask.sum()}\")\n",
    "print(f\"  - Q1 2025 resignations (Jan-Mar): {len(q1_resignations)}\")\n",
    "print(f\"  - Q2 2025 resignations (Apr-Jun): {len(q2_resignations)}\")\n",
    "print(f\"  - Other resignations: {len(other_resignations)}\")\n",
    "print(f\"Current employees (no resignation date): {len(extended_df) - resigned_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce31bb0",
   "metadata": {},
   "source": [
    "#### Print columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c5ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "\n",
      "First five rows of the dataset:\n",
      "+-------------+------------------+--------+-----+------------+------------+------------------+-----------------+-------------------+----------------+---------------------+------------------+----------------+-----------+-----------------------+-----------+----------------+------------+-----------------------------+----------+------------------+\n",
      "| Employee_ID |    Department    | Gender | Age | Job_Title  | Hire_Date  | Years_At_Company | Education_Level | Performance_Score | Monthly_Salary | Work_Hours_Per_Week | Projects_Handled | Overtime_Hours | Sick_Days | Remote_Work_Frequency | Team_Size | Training_Hours | Promotions | Employee_Satisfaction_Score | Resigned | Resignation_Date |\n",
      "+-------------+------------------+--------+-----+------------+------------+------------------+-----------------+-------------------+----------------+---------------------+------------------+----------------+-----------+-----------------------+-----------+----------------+------------+-----------------------------+----------+------------------+\n",
      "|      1      |        IT        |  Male  | 55  | Specialist | 19/01/2022 |        2         |   High School   |         5         |      6750      |         33          |        32        |       22       |     2     |          57           |    14     |       66       |     0      |            2.63             |  False   |       nan        |\n",
      "|      2      |     Finance      |  Male  | 29  | Developer  | 18/04/2024 |        0         |   High School   |         5         |      7500      |         34          |        34        |       13       |    14     |          40           |    12     |       61       |     2      |            1.72             |  False   |       nan        |\n",
      "|      4      | Customer Support | Female | 48  |  Analyst   | 26/10/2015 |        7         |    Bachelor     |         2         |      4800      |         52          |        10        |       28       |    12     |          68           |    10     |       0        |     1      |            1.86             |   True   |    23/04/2022    |\n",
      "|      5      |   Engineering    | Female | 36  |  Analyst   | 22/10/2016 |        3         |    Bachelor     |         2         |      4800      |         38          |        11        |       29       |    13     |          58           |    15     |       9        |     1      |            1.25             |   True   |    16/10/2024    |\n",
      "|      6      |        IT        |  Male  | 43  |  Manager   | 23/07/2021 |        8         |   High School   |         3         |      7800      |         46          |        31        |       8        |     0     |          80           |    15     |       95       |     0      |            2.77             |  False   |       nan        |\n",
      "+-------------+------------------+--------+-----+------------+------------+------------------+-----------------+-------------------+----------------+---------------------+------------------+----------------+-----------+-----------------------+-----------+----------------+------------+-----------------------------+----------+------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "from tabulate import tabulate\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"Deployment_Used_Extended_Dataset_with_Resignation.csv\"\n",
    "\n",
    "if os.path.isfile(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "    print(\"\\nFirst five rows of the dataset:\")\n",
    "    print(tabulate(df.head(), headers='keys', tablefmt='pretty', showindex=False))\n",
    "else:\n",
    "    print(f\"Error: The file '{file_path}' was not found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9e28c6",
   "metadata": {},
   "source": [
    "#### Show the currnt columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd1d84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Employee_ID', 'Department', 'Gender', 'Age', 'Job_Title', 'Hire_Date',\n",
      "       'Years_At_Company', 'Education_Level', 'Performance_Score',\n",
      "       'Monthly_Salary', 'Work_Hours_Per_Week', 'Projects_Handled',\n",
      "       'Overtime_Hours', 'Sick_Days', 'Remote_Work_Frequency', 'Team_Size',\n",
      "       'Training_Hours', 'Promotions', 'Employee_Satisfaction_Score',\n",
      "       'Resigned', 'Resignation_Date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
